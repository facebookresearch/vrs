"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3012],{29933:(e,i,a)=>{a.r(i),a.d(i,{assets:()=>s,contentTitle:()=>d,default:()=>h,frontMatter:()=>t,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"ImageSupport","title":"Image Support","description":"This page describes how VRS handles content blocks using the Datalayout Conventions.","source":"@site/docs/ImageSupport.md","sourceDirName":".","slug":"/ImageSupport","permalink":"/vrs/docs/ImageSupport","draft":false,"unlisted":false,"editUrl":"https://github.com/facebookresearch/vrs/edit/main/website/docs/ImageSupport.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7,"title":"Image Support"},"sidebar":"tutorialSidebar","previous":{"title":"Record Format","permalink":"/vrs/docs/RecordFormat"},"next":{"title":"The FileHandler Interface","permalink":"/vrs/docs/FileHandler"}}');var n=a(74848),r=a(28453);const t={sidebar_position:7,title:"Image Support"},d=void 0,s={},c=[{value:"Additional Image Properties",id:"additional-image-properties",level:2},{value:"Specifying Additional Image Properties",id:"specifying-additional-image-properties",level:3},{value:"Image Format Differences",id:"image-format-differences",level:2},{value:"<code>image/raw</code>",id:"imageraw",level:3},{value:"<code>image/png</code>, <code>image/jpg</code> and <code>image/jxl</code>",id:"imagepng-imagejpg-and-imagejxl",level:3},{value:"<code>image/custom_codec</code>",id:"imagecustom_codec",level:3},{value:"<code>image/video</code>",id:"imagevideo",level:3},{value:"Reading Images",id:"reading-images",level:2},{value:"<code>image/raw</code> images",id:"imageraw-images",level:3},{value:"<code>image/png</code>, <code>image/jpg</code>, and <code>image/jxl</code> images",id:"imagepng-imagejpg-and-imagejxl-images",level:3},{value:"<code>image/custom_codec</code> images",id:"imagecustom_codec-images",level:3},{value:"<code>image/video</code> images",id:"imagevideo-images",level:3}];function l(e){const i={a:"a",br:"br",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(i.p,{children:(0,n.jsx)(i.em,{children:"This page describes how VRS handles content blocks using the Datalayout Conventions."})}),"\n",(0,n.jsxs)(i.p,{children:["Prerequisite: Understanding how ",(0,n.jsx)(i.code,{children:"RecordFormat"})," works."]}),"\n",(0,n.jsx)(i.p,{children:"Image content blocks can be any of the following different subtypes:"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.code,{children:"image/raw"}),(0,n.jsx)(i.br,{}),"\n","The image is stored as a buffer of raw pixels, which might a compacted pixel format such as ",(0,n.jsx)(i.a,{href:"https://developer.android.com/reference/android/graphics/ImageFormat#RAW10",children:"RAW10"}),", but not compressed using a ",(0,n.jsx)(i.code,{children:"PixelFormat"}),".",(0,n.jsx)(i.br,{}),"\n","The exact ",(0,n.jsx)(i.a,{href:"https://github.com/facebookresearch/vrs/blob/main/vrs/RecordFormat.h#L63-L92",children:"list of pixel formats"})," grows over time."]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.code,{children:"image/png"}),", ",(0,n.jsx)(i.code,{children:"image/jpg"}),", ",(0,n.jsx)(i.code,{children:"image/jxl"}),", and ",(0,n.jsx)(i.code,{children:"image/custom_codec"}),(0,n.jsx)(i.br,{}),"\n","The image is compressed using png, jpeg, jpeg-xl, or a custom codec. The payload of the image content block contains exactly what regular file of that image type would contain",(0,n.jsx)(i.br,{}),"\n",(0,n.jsx)(i.em,{children:"Note that when using a custom codec, you must specify a codec name, or the image content block will be reported as unsupported on read."})]}),"\n",(0,n.jsxs)(i.li,{children:[(0,n.jsx)(i.code,{children:"image/video"}),(0,n.jsx)(i.br,{}),"\n","The image is compressed according to the spec of a video codec standard, such as H.264 or H.265.",(0,n.jsx)(i.br,{}),"\n",(0,n.jsx)(i.em,{children:"Note that the list of supported video codecs is deliberately not part of the spec, but rather, is meant to be implementation dependent, by an extension. VRS Open Source provides the vrs/xprs module to interface with ffmpeg and expose the codecs it was built with."})]}),"\n"]}),"\n",(0,n.jsx)(i.h2,{id:"additional-image-properties",children:"Additional Image Properties"}),"\n",(0,n.jsxs)(i.p,{children:["To be complete, image content blocks, in particular ",(0,n.jsx)(i.code,{children:"image/raw"})," content blocks, may require the following complementary properties for an image:"]}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsx)(i.li,{children:"Resolution"}),"\n",(0,n.jsx)(i.li,{children:"Stride"}),"\n",(0,n.jsx)(i.li,{children:"Pixel format"}),"\n"]}),"\n",(0,n.jsxs)(i.p,{children:["Without these properties, ",(0,n.jsx)(i.code,{children:"image/raw"})," images cannot be interpreted safely. These properties can be provided in two distinct ways:"]}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsxs)(i.li,{children:["The image properties can be part of the ",(0,n.jsx)(i.code,{children:"RecordFormat"})," description itself, meaning that the records using that ",(0,n.jsx)(i.code,{children:"RecordFormat"})," will all be using the exact same pixel format.",(0,n.jsx)(i.br,{}),"\n","The content block description might look like this:","\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsx)(i.li,{children:(0,n.jsx)(i.code,{children:"image/raw/640x480/pixel=grey8"})}),"\n",(0,n.jsx)(i.li,{children:(0,n.jsx)(i.code,{children:"image/raw/640x480/pixel=yuv_i420_split/stride=640"})}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(i.li,{children:["The image properties can be provided in the datalayout content block found either before the ",(0,n.jsx)(i.code,{children:"image"})," content block in the same record, or in the stream\u2019s last configuration record. When using this method, the properties must be specified using the ",(0,n.jsx)(i.a,{href:"https://github.com/facebookresearch/vrs/blob/main/vrs/DataLayoutConventions.h#L61-L64",children:"Datalayout Conventions"}),", which are merely a collection of data types and labels to use in your ",(0,n.jsx)(i.code,{children:"DataLayout"})," to specify properties."]}),"\n"]}),"\n",(0,n.jsxs)(i.p,{children:["Whichever method you use, VRS collects the image properties for you, so that the ",(0,n.jsx)(i.code,{children:"RecordFormatStreamPlayer::onImageRead()"})," callback can directly provide a content block object that you can query for the image format, regardless of how or where it was specified."]}),"\n",(0,n.jsx)(i.h3,{id:"specifying-additional-image-properties",children:"Specifying Additional Image Properties"}),"\n",(0,n.jsxs)(i.p,{children:["For ",(0,n.jsx)(i.code,{children:"image/raw"})," and ",(0,n.jsx)(i.code,{children:"image/video"})," images, use a ",(0,n.jsx)(i.a,{href:"https://github.com/facebookresearch/vrs/blob/main/vrs/DataLayoutConventions.h#L59",children:(0,n.jsx)(i.code,{children:"vrs::DataLayoutConventions::ImageSpec"})})," to describe your image in a configuration record, or in a ",(0,n.jsx)(i.code,{children:"DataLayout"})," block just before the image content block of your data records."]}),"\n",(0,n.jsxs)(i.p,{children:["The ",(0,n.jsx)(i.code,{children:"DataLayout"})," fields are:"]}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-cpp",children:"  DataPieceValue<ImageSpecType> width{kImageWidth};\n  DataPieceValue<ImageSpecType> height{kImageHeight};\n  DataPieceValue<ImageSpecType> stride{kImageStride};\n  DataPieceValue<ImageSpecType> stride2{kImageStride2};\n  DataPieceEnum<PixelFormat, ImageSpecType> pixelFormat{kImagePixelFormat};\n\n  // For image/custom_codec and image/video only\n  DataPieceString codecName{kImageCodecName}; // required\n  DataPieceValue<ImageSpecType> codecQuality{kImageCodecQuality}; // optional\n"})}),"\n",(0,n.jsxs)(i.p,{children:["For ",(0,n.jsx)(i.code,{children:"image/video"})," images, specify the keyframe timestamp and the keyframe index, using the following ",(0,n.jsx)(i.code,{children:"DataLayout"})," fields:"]}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-cpp",children:"  DataPieceValue<double> keyFrameTimestamp{kImageKeyFrameTimeStamp};\n  DataPieceValue<ImageSpecType> keyFrameIndex{kImageKeyFrameIndex};\n"})}),"\n",(0,n.jsx)(i.h2,{id:"image-format-differences",children:"Image Format Differences"}),"\n",(0,n.jsx)(i.h3,{id:"imageraw",children:(0,n.jsx)(i.code,{children:"image/raw"})}),"\n",(0,n.jsxs)(i.p,{children:["Without the following properties, ",(0,n.jsx)(i.code,{children:"image/raw"})," image content blocks can not be interpreted:"]}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsx)(i.li,{children:"Required properties: width, height, pixel format."}),"\n",(0,n.jsx)(i.li,{children:"Optional properties: stride, stride2."}),"\n"]}),"\n",(0,n.jsxs)(i.p,{children:["When properties are provided using the Datalayout Conventions, all additional properties must be provided by a single ",(0,n.jsx)(i.code,{children:"DataLayout"})," structure in one record. For example, you must not put the pixel format in the configuration record, and then put the image dimensions in the data record. You must either put both the pixel format and the image dimensions in a configuration record's ",(0,n.jsx)(i.code,{children:"DataLayout"}),", or you must put them both in a ",(0,n.jsx)(i.code,{children:"DataLayout"})," just before the image content block."]}),"\n",(0,n.jsxs)(i.h3,{id:"imagepng-imagejpg-and-imagejxl",children:[(0,n.jsx)(i.code,{children:"image/png"}),", ",(0,n.jsx)(i.code,{children:"image/jpg"})," and ",(0,n.jsx)(i.code,{children:"image/jxl"})]}),"\n",(0,n.jsx)(i.p,{children:"png, jpg, and jxl payloads are exactly the same as png, jpg, and jxl files, which are fully self-described. Therefore, when those image formats are used, properties specified using the Datalayout Conventions are ignored by VRS."}),"\n",(0,n.jsx)(i.h3,{id:"imagecustom_codec",children:(0,n.jsx)(i.code,{children:"image/custom_codec"})}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsx)(i.li,{children:"Required properties: codec name."}),"\n",(0,n.jsx)(i.li,{children:"Optional properties: width, height, pixel format, codec name, keyframe timestamp, keyframe index."}),"\n"]}),"\n",(0,n.jsx)(i.p,{children:"The only property VRS itself requires is a codec name for an image content block to be recognized. However, a particular custom codec may require additional properties, such as width, height, and pixel format. Whether a custom codec requires that information or not an implementation detail of each specific custom codec. VRS does not support any particular custom codec by default, they are meant for experimentations and special cases."}),"\n",(0,n.jsx)(i.h3,{id:"imagevideo",children:(0,n.jsx)(i.code,{children:"image/video"})}),"\n",(0,n.jsx)(i.p,{children:"Video image content blocks require additional properties to decode images:"}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsx)(i.li,{children:"Required properties: width, height, pixel format, codec name, keyframe timestamp, keyframe index."}),"\n",(0,n.jsx)(i.li,{children:"Optional properties: compression quality, which may affect how to decode the image."}),"\n"]}),"\n",(0,n.jsxs)(i.p,{children:["Similar to ",(0,n.jsx)(i.code,{children:"image/raw"})," images, pixel format and image dimension information must be provided in a single ",(0,n.jsx)(i.code,{children:"DataLayout"}),", either in the configuration record or in the data record of the image. Typically, the pixel format and image resolution will not change without a configuration change. Therefore, they are best stored in a configuration record.",(0,n.jsx)(i.br,{}),"\n","On the other hand, the keyframe timestamp and the keyframe index properties change with every frame, and are therefore searched only in a ",(0,n.jsx)(i.code,{children:"DataLayout"})," that must be immediately before the ",(0,n.jsx)(i.code,{children:"image/video"})," content block."]}),"\n",(0,n.jsx)(i.h2,{id:"reading-images",children:"Reading Images"}),"\n",(0,n.jsxs)(i.p,{children:["Image data is received by the ",(0,n.jsx)(i.code,{children:"RecordFormatStreamPlayer::onImageRead()"})," callback:"]}),"\n",(0,n.jsx)(i.pre,{children:(0,n.jsx)(i.code,{className:"language-cpp",children:"bool onImageRead(\n    const CurrentRecord& record,\n    size_t blockIndex,\n    const ContentBlock& contentBlock);\n"})}),"\n",(0,n.jsxs)(i.p,{children:["The ",(0,n.jsx)(i.code,{children:"RecordFormatStreamPlayer::onDataLayoutRead()"})," callback happens ",(0,n.jsx)(i.strong,{children:"after"})," the ",(0,n.jsx)(i.code,{children:"DataLayout"})," data has been read from disk."]}),"\n",(0,n.jsxs)(i.p,{children:["The ",(0,n.jsx)(i.code,{children:"RecordFormatStreamPlayer::onImageRead()"})," callback happens ",(0,n.jsx)(i.strong,{children:"before"})," any image data has been read. However, the provided ",(0,n.jsx)(i.code,{children:"contentBlock"})," object holds all the image properties, so the following information can be found:"]}),"\n",(0,n.jsxs)(i.ul,{children:["\n",(0,n.jsxs)(i.li,{children:["For all types: the ",(0,n.jsx)(i.code,{children:"contentBlock"})," size is known. That's the size of the buffer you will need to read the image data stored in the image content block."]}),"\n",(0,n.jsxs)(i.li,{children:["For ",(0,n.jsx)(i.code,{children:"image/raw"})," images: resolution, strides, and pixel format are defined."]}),"\n",(0,n.jsxs)(i.li,{children:["For ",(0,n.jsx)(i.code,{children:"image/custom_codec"})," images: codec name is defined. Resolution, strides, and pixel format might be defined too, if provided in the stream using the Datalayout Conventions."]}),"\n",(0,n.jsxs)(i.li,{children:["For ",(0,n.jsx)(i.code,{children:"image/video"})," images: the pixel format, resolution, codec name, keyframe timestamp, and keyframe index are defined."]}),"\n"]}),"\n",(0,n.jsxs)(i.p,{children:["The image data itself can be read using the ",(0,n.jsx)(i.code,{children:"RecordReader"})," object provided by the ",(0,n.jsx)(i.code,{children:"CurrentRecord"})," object. The image is described by an ",(0,n.jsx)(i.code,{children:"ImageContentBlockSpec"})," object provided by ",(0,n.jsx)(i.code,{children:"contentBlock.image()"}),"."]}),"\n",(0,n.jsxs)(i.h3,{id:"imageraw-images",children:[(0,n.jsx)(i.code,{children:"image/raw"})," images"]}),"\n",(0,n.jsxs)(i.p,{children:["Allocate or reuse a buffer where you can read the image data. Be careful to properly handle the image\u2019s stride and stride2. ",(0,n.jsx)(i.code,{children:"stride"})," describes the stride of the first plane (the number of bytes separating the first byte of each successive lines), while ",(0,n.jsx)(i.code,{children:"stride2"})," describes the stride of all the following planes, if the images is stored in a multi-plane format."]}),"\n",(0,n.jsxs)(i.h3,{id:"imagepng-imagejpg-and-imagejxl-images",children:[(0,n.jsx)(i.code,{children:"image/png"}),", ",(0,n.jsx)(i.code,{children:"image/jpg"}),", and ",(0,n.jsx)(i.code,{children:"image/jxl"})," images"]}),"\n",(0,n.jsx)(i.p,{children:"You will need to read and decode the compressed image data using a standard implementation."}),"\n",(0,n.jsxs)(i.h3,{id:"imagecustom_codec-images",children:[(0,n.jsx)(i.code,{children:"image/custom_codec"})," images"]}),"\n",(0,n.jsx)(i.p,{children:"You will need to read and decode the compressed image data using your own implementation of the custom codec, which implementation is presumably unknown to VRS."}),"\n",(0,n.jsxs)(i.h3,{id:"imagevideo-images",children:[(0,n.jsx)(i.code,{children:"image/video"})," images"]}),"\n",(0,n.jsxs)(i.p,{children:["Support for ",(0,n.jsx)(i.code,{children:"image/video"})," images is provided by the vrs/xprs module, that depends on ffmpeg, and exposes the codecs built with it."]})]})}function h(e={}){const{wrapper:i}={...(0,r.R)(),...e.components};return i?(0,n.jsx)(i,{...e,children:(0,n.jsx)(l,{...e})}):l(e)}}}]);