"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3012],{29933:(e,i,a)=>{a.r(i),a.d(i,{assets:()=>s,contentTitle:()=>d,default:()=>h,frontMatter:()=>t,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"ImageSupport","title":"Image Support","description":"This page describes how VRS handles content blocks using the Datalayout Conventions.","source":"@site/docs/ImageSupport.md","sourceDirName":".","slug":"/ImageSupport","permalink":"/vrs/docs/ImageSupport","draft":false,"unlisted":false,"editUrl":"https://github.com/facebookresearch/vrs/edit/main/website/docs/ImageSupport.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7,"title":"Image Support"},"sidebar":"tutorialSidebar","previous":{"title":"Record Format","permalink":"/vrs/docs/RecordFormat"},"next":{"title":"The FileHandler Interface","permalink":"/vrs/docs/FileHandler"}}');var r=a(74848),o=a(28453);const t={sidebar_position:7,title:"Image Support"},d=void 0,s={},c=[{value:"Additional Image Properties",id:"additional-image-properties",level:2},{value:"Specifying Additional Image Properties",id:"specifying-additional-image-properties",level:3},{value:"Image Format Differences",id:"image-format-differences",level:2},{value:"<code>image/raw</code>",id:"imageraw",level:3},{value:"<code>image/jpg</code> and <code>image/png</code>",id:"imagejpg-and-imagepng",level:3},{value:"<code>image/video</code>",id:"imagevideo",level:3},{value:"Reading Images",id:"reading-images",level:2},{value:"<code>image/raw</code> images",id:"imageraw-images",level:3},{value:"<code>image/jpg</code> and <code>image/png</code> images",id:"imagejpg-and-imagepng-images",level:3},{value:"<code>image/video</code> images",id:"imagevideo-images",level:3}];function l(e){const i={a:"a",br:"br",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(i.p,{children:(0,r.jsx)(i.em,{children:"This page describes how VRS handles content blocks using the Datalayout Conventions."})}),"\n",(0,r.jsxs)(i.p,{children:["Prerequisite: Understanding how ",(0,r.jsx)(i.code,{children:"RecordFormat"})," works."]}),"\n",(0,r.jsx)(i.p,{children:"Image content blocks can be any of the following different subtypes:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.code,{children:"image/raw"}),(0,r.jsx)(i.br,{}),"\n","The image is stored as a buffer of raw pixels, which might a compacted pixel format such as ",(0,r.jsx)(i.a,{href:"https://developer.android.com/reference/android/graphics/ImageFormat#RAW10",children:"RAW10"}),", but not compressed using a ",(0,r.jsx)(i.code,{children:"PixelFormat"}),".",(0,r.jsx)(i.br,{}),"\n","The exact ",(0,r.jsx)(i.a,{href:"https://github.com/facebookresearch/vrs/blob/main/vrs/RecordFormat.h#L49-L68",children:"list of pixel formats"})," grows over time."]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.code,{children:"image/jpg"})," and ",(0,r.jsx)(i.code,{children:"image/png"}),(0,r.jsx)(i.br,{}),"\n","The image is compressed using jpeg or png compression. The payload of the image content block contains exactly what a jpg or png file would contain."]}),"\n",(0,r.jsxs)(i.li,{children:[(0,r.jsx)(i.code,{children:"image/video"}),(0,r.jsx)(i.br,{}),"\n","The image is compressed according to the spec of a video codec standard, such as H.264 or H.265.",(0,r.jsx)(i.br,{}),"\n",(0,r.jsx)(i.em,{children:"Note that the list of supported video codecs is deliberately not part of the spec, but rather, is meant to be implementation dependent, part of a VRS extension. VRS Open Source does not currently provide any implementation."})]}),"\n"]}),"\n",(0,r.jsx)(i.h2,{id:"additional-image-properties",children:"Additional Image Properties"}),"\n",(0,r.jsxs)(i.p,{children:["To be complete, image content blocks, in particular ",(0,r.jsx)(i.code,{children:"image/raw"})," content blocks, may require the following complementary properties for an image:"]}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Resolution"}),"\n",(0,r.jsx)(i.li,{children:"Stride"}),"\n",(0,r.jsx)(i.li,{children:"Pixel format"}),"\n"]}),"\n",(0,r.jsxs)(i.p,{children:["Without these properties, ",(0,r.jsx)(i.code,{children:"image/raw"})," images cannot be interpreted safely. These properties can be provided in two distinct ways:"]}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["The image properties can be part of the ",(0,r.jsx)(i.code,{children:"RecordFormat"})," description itself, meaning that the records using that ",(0,r.jsx)(i.code,{children:"RecordFormat"})," will all be using the exact same pixel format.",(0,r.jsx)(i.br,{}),"\n","The content block description might look like this:","\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:(0,r.jsx)(i.code,{children:"image/raw/640x480/pixel=grey8"})}),"\n",(0,r.jsx)(i.li,{children:(0,r.jsx)(i.code,{children:"image/raw/640x480/pixel=yuv_i420_split/stride=640"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(i.li,{children:["The image properties can be provided in the datalayout content block found either before the ",(0,r.jsx)(i.code,{children:"image"})," content block in the same record, or in the stream\u2019s last configuration record. When using this method, the properties must be specified using the ",(0,r.jsx)(i.a,{href:"https://github.com/facebookresearch/vrs/blob/main/vrs/DataLayoutConventions.h#L61-L64",children:"Datalayout Conventions"}),", which are merely a collection of data types and labels to use in your ",(0,r.jsx)(i.code,{children:"DataLayout"})," to specify properties."]}),"\n"]}),"\n",(0,r.jsxs)(i.p,{children:["Whichever method you use, VRS collects the image properties for you, so that the ",(0,r.jsx)(i.code,{children:"RecordFormatStreamPlayer::onImageRead()"})," callback can directly provide a content block object that you can query for the image format, regardless of how or where it was specified."]}),"\n",(0,r.jsx)(i.h3,{id:"specifying-additional-image-properties",children:"Specifying Additional Image Properties"}),"\n",(0,r.jsxs)(i.p,{children:["For ",(0,r.jsx)(i.code,{children:"image/raw"})," and ",(0,r.jsx)(i.code,{children:"image/video"})," images, use a ",(0,r.jsx)(i.a,{href:"https://github.com/facebookresearch/vrs/blob/main/vrs/DataLayoutConventions.h#L59",children:(0,r.jsx)(i.code,{children:"vrs::DataLayoutConventions::ImageSpec"})})," to describe your image in a configuration record, or in a ",(0,r.jsx)(i.code,{children:"DataLayout"})," block just before the image content block of your data records."]}),"\n",(0,r.jsxs)(i.p,{children:["The ",(0,r.jsx)(i.code,{children:"DataLayout"})," fields are:"]}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-cpp",children:"  DataPieceValue<ImageSpecType> width{kImageWidth};\n  DataPieceValue<ImageSpecType> height{kImageHeight};\n  DataPieceValue<ImageSpecType> stride{kImageStride};\n  DataPieceEnum<PixelFormat, ImageSpecType> pixelFormat{kImagePixelFormat};\n\n  // For image/video only\n  DataPieceString codecName{kImageCodecName}; // required\n  DataPieceValue<ImageSpecType> codecQuality{kImageCodecQuality}; // optional\n"})}),"\n",(0,r.jsxs)(i.p,{children:["For ",(0,r.jsx)(i.code,{children:"image/video"})," images, specify the keyframe timestamp and the keyframe index, using the following ",(0,r.jsx)(i.code,{children:"DataLayout"})," fields:"]}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-cpp",children:"  DataPieceValue<double> keyFrameTimestamp{kImageKeyFrameTimeStamp};\n  DataPieceValue<ImageSpecType> keyFrameIndex{kImageKeyFrameIndex};\n"})}),"\n",(0,r.jsx)(i.h2,{id:"image-format-differences",children:"Image Format Differences"}),"\n",(0,r.jsx)(i.h3,{id:"imageraw",children:(0,r.jsx)(i.code,{children:"image/raw"})}),"\n",(0,r.jsxs)(i.p,{children:["Without the following properties, ",(0,r.jsx)(i.code,{children:"image/raw"})," image content blocks can not be interpreted:"]}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Required properties: width, height, pixel format."}),"\n",(0,r.jsx)(i.li,{children:"Optional properties: stride."}),"\n"]}),"\n",(0,r.jsxs)(i.p,{children:["When properties are provided using the Datalayout Conventions, all additional properties must be provided by a single ",(0,r.jsx)(i.code,{children:"DataLayout"})," structure in one record. For example, you must not put the pixel format in the configuration record, and then put the image dimensions in the data record. You must either put both the pixel format and the image dimensions in a configuration record's ",(0,r.jsx)(i.code,{children:"DataLayout"}),", or you must put them both in a ",(0,r.jsx)(i.code,{children:"DataLayout"})," just before the image content block."]}),"\n",(0,r.jsxs)(i.h3,{id:"imagejpg-and-imagepng",children:[(0,r.jsx)(i.code,{children:"image/jpg"})," and ",(0,r.jsx)(i.code,{children:"image/png"})]}),"\n",(0,r.jsx)(i.p,{children:"jpg and png payloads are exactly the same as jpg and png files, which are fully self-described. Therefore, when those image formats are used, properties specified using the Datalayout Conventions are ignored by VRS."}),"\n",(0,r.jsx)(i.h3,{id:"imagevideo",children:(0,r.jsx)(i.code,{children:"image/video"})}),"\n",(0,r.jsx)(i.p,{children:(0,r.jsxs)(i.em,{children:["Support for ",(0,r.jsx)(i.code,{children:"image/video"})," images is not ready for open sourcing at this time."]})}),"\n",(0,r.jsx)(i.p,{children:"Video image content blocks require additional properties to decode images:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Required properties: width, height, pixel format, codec name, keyframe timestamp, keyframe index."}),"\n",(0,r.jsx)(i.li,{children:"Optional properties: compression quality, which may affect how to decode the image."}),"\n"]}),"\n",(0,r.jsxs)(i.p,{children:["Similar to ",(0,r.jsx)(i.code,{children:"image/raw"})," images, pixel format and image dimension information must be provided in a single ",(0,r.jsx)(i.code,{children:"DataLayout"}),", either in the configuration record or in the data record of the image. Typically, the pixel format and image resolution will not change without a configuration change. Therefore, they are best stored in a configuration record.",(0,r.jsx)(i.br,{}),"\n","On the other hand, the keyframe timestamp and the keyframe index properties change with every frame, and are therefore searched only in a ",(0,r.jsx)(i.code,{children:"DataLayout"})," that must be immediately before the ",(0,r.jsx)(i.code,{children:"image/video"})," content block."]}),"\n",(0,r.jsx)(i.h2,{id:"reading-images",children:"Reading Images"}),"\n",(0,r.jsxs)(i.p,{children:["Image data is received by the ",(0,r.jsx)(i.code,{children:"RecordFormatStreamPlayer::onImageRead()"})," callback:"]}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-cpp",children:"bool onImageRead(\n    const CurrentRecord& record,\n    size_t blockIndex,\n    const ContentBlock& contentBlock);\n"})}),"\n",(0,r.jsxs)(i.p,{children:["The ",(0,r.jsx)(i.code,{children:"RecordFormatStreamPlayer::onDataLayoutRead()"})," callback happens ",(0,r.jsx)(i.strong,{children:"after"})," the ",(0,r.jsx)(i.code,{children:"DataLayout"})," data has been read from disk."]}),"\n",(0,r.jsxs)(i.p,{children:["The ",(0,r.jsx)(i.code,{children:"RecordFormatStreamPlayer::onImageRead()"})," callback happens ",(0,r.jsx)(i.strong,{children:"before"})," any image data has been read. However, the provided ",(0,r.jsx)(i.code,{children:"contentBlock"})," object holds all the image properties, so the following information can be found:"]}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsxs)(i.li,{children:["For all types: the ",(0,r.jsx)(i.code,{children:"contentBlock"})," size is known. That's the size of the buffer you will need to read the image data stored in the image content block."]}),"\n",(0,r.jsxs)(i.li,{children:["For ",(0,r.jsx)(i.code,{children:"image/raw"})," images: the pixel format and resolution are defined."]}),"\n",(0,r.jsxs)(i.li,{children:["For ",(0,r.jsx)(i.code,{children:"image/video"})," images: the pixel format, resolution, keyframe timestamp, and keyframe index are defined."]}),"\n"]}),"\n",(0,r.jsxs)(i.p,{children:["The image data itself can be read using the ",(0,r.jsx)(i.code,{children:"RecordReader"})," object provided by the ",(0,r.jsx)(i.code,{children:"CurrentRecord"})," object. The image is described by an ",(0,r.jsx)(i.code,{children:"ImageContentBlockSpec"})," object provided by ",(0,r.jsx)(i.code,{children:"contentBlock.image()"}),"."]}),"\n",(0,r.jsxs)(i.h3,{id:"imageraw-images",children:[(0,r.jsx)(i.code,{children:"image/raw"})," images"]}),"\n",(0,r.jsx)(i.p,{children:"Allocate or reuse a buffer where you can read the image data. Beware of the image\u2019s stride, which is how it was when the image was saved."}),"\n",(0,r.jsxs)(i.h3,{id:"imagejpg-and-imagepng-images",children:[(0,r.jsx)(i.code,{children:"image/jpg"})," and ",(0,r.jsx)(i.code,{children:"image/png"})," images"]}),"\n",(0,r.jsx)(i.p,{children:"You will need to read and decode the compressed image data using a standard jpg or png library."}),"\n",(0,r.jsxs)(i.h3,{id:"imagevideo-images",children:[(0,r.jsx)(i.code,{children:"image/video"})," images"]}),"\n",(0,r.jsxs)(i.p,{children:["Support for ",(0,r.jsx)(i.code,{children:"image/video"})," images is not currently ready for open sourcing. Stay tuned!"]})]})}function h(e={}){const{wrapper:i}={...(0,o.R)(),...e.components};return i?(0,r.jsx)(i,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}}}]);